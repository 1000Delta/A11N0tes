\documentclass[11pt]{book}
\usepackage{fontspec, xunicode, xltxtra}
\usepackage[tmargin=1in,bmargin=1in,lmargin=1.25in,rmargin=1.25in]{geometry}
\usepackage{ctex}
\usepackage{amsmath}

\begin{document}
\title{模式识别导论}
\author{DX}
\date{2019-09-21}

\chapter{绪论}

\chapter{聚类分析}

\section{距离聚类的概念}

\section{相似性测度和聚类准则}

\section{基于距离阈值的聚类算法}

\section{层次聚类法}

\section{动态聚类法}

聚类过程中，聚类中心位置或个数发生变化.

两种常用的算法：
\begin{itemize}
	\item K - 均值算法（或 C - 均值算法）
	\item 迭代自组织的数据分析算法
\end{itemize}

\subsection{K - 均值算法}%

基于使聚类准则函数最小化。

\paragraph{准则函数}%
\label{par:zhun_ze_han_shu_}

聚类集中每一样本点到该类中心的距离平方和。

对于第j个聚集类，准则函数定义为：
$$
   J_j	= \sum^{N_j}_{i=1} || X_i - Z_j ||^2, X_i \in S_j
$$

\paragraph{算法描述}%
\label{par:suan_fa_miao_shu_}

\paragraph{算法讨论}%
\label{par:suan_fa_tao_lun_}

\paragraph{聚类准则函数 $J_k$ 与 $K$ 的关系曲线}%
\label{par:ju_lei_zhun_ze_han_shu_j_k_yu_k_de_guan_xi_qu_xian_}

\subsection{迭代自组织的数据分析算法}%

迭代自组织的数据分析算法也常称为 ISODATA 算法 (Iterate Selft-Organizing Data Analysis Techniques Algorithm, ISODATA).

\paragraph{算法特点}%
\label{par:suan_fa_te_dian_}

\begin{itemize}
	\item 加入了试探性步骤，组成人机交互的结构；
	\item 可以通过类的自动合并与分裂得到较合理的类别数。
\end{itemize}

\paragraph{基本思路}%
\label{par:ji_ben_si_lu_}

\begin{enumerate}
	\item 选择初始值
	\item 按最邻近规则进行分类
	\item 聚类后的处理：计算各类中的距离函数等指标
	\item 判断结果是否符合要求，符合则结束，否则回到2
\end{enumerate}

\paragraph{算法描述}%
\label{par:suan_fa_miao_shu_}

P31

\paragraph{常用指标}%
\label{par:chang_yong_zhi_biao_}

各指标综合考虑

\begin{enumerate}
	\item 聚类中心之间的距离
	\item 诸聚类域中样本数目
	\item 诸聚类域中样本的标准差向量
\end{enumerate}

\chapter{判别函数及几何分类法}

\section{判别函数}

统计模式识别
$$
	\left\{
	\begin{array}{ll}
		& \mbox{聚类分析法（第二章）} \\
		& \mbox{判别函数法} 
		\left\{
		\begin{array}{ll}
			\left.
			& 
			\begin{array}{ll}
				\mbox{线性判别函数法} \\
				\mbox{非线性判别函数法} \\
			\end{array}
			\right\} => xx \\
			& \mbox{统计决策方法}
		\end{array}
		\right.
	\end{array}
	\right.
$$
\subsection{判别函数}%

\paragraph{定义}%
\label{par:ding_yi_}

直接用来对模式进行分类的准则函数。

\section{线性判别函数}

\subsection{线性判别函数的一般形式}

$$
d(\mathbf X) = w_1x_1 + w_2x_2 + \ldots + w_nx_n + w_{n+1} = \mathbf{W}^T_0 \mathbf{X} w_{n+1}
$$
式中，$\mathbf{W}_0 = [w_1, w_2, \ldots, w_n]^T$ 称为权向量或参数向量；$\mathbf{X} = [x_1, x_2, \ldots, x_n]^T$ 是 $n$ 维特征向量，又称模式向量或样本向量；$w_{n+1}$ 是常数，称为阈值权。


\subsection{线性判别函数的性质}

\subsubsection{两类情况}%
\label{ssub:liang_lei_qing_kuang_}

若已知两类模式 $\omega_1$ 和 $\omega_2$

\section{广义线性判别函数}

\section{线性判别函数的集合性质}

\section{感知器算法}

\subsection{前置概念}

\paragraph{训练与学习}%
\label{par:xun_lian_yu_xue_xi_}

\paragraph{确定性分类器}%
\label{par:que_ding_xing_fen_lei_qi_}

\paragraph{感知器}%
\label{par:gan_zhi_qi_}

感知器（preception）是一种神经网络模型，$\ldots$

\subsection{算法描述}

\paragraph{规范化处理}%
\label{par:gui_fan_hua_chu_li_}

将第二类样本全部乘以 $(-1)$ 使得对于所有两类样本，判别函数的性质描述为
\begin{equation}
	d(\mathbf X) = \mathbf W^T \mathbf X > 0
\end{equation}

\paragraph{算法步骤}%
\label{par:suan_fa_bu_zou_}

P54


感知器算法就是一种赏罚过程：当分类器发生分类错误时，对分类器进行“罚”---修改权向量，使其向正确的方向转换；分类正确时，对其进行“赏”---这里表现为“不罚”，即权向量不变。

\subsection{收敛性}

经过算法的有限次迭代运算后，求出一个使训练集中所有样本都能正确分类的 $W$，则称算法是收敛的。可以证明感知器算法是收敛的。

\subsection{感知器算法用于多类情况}

转化成多个二类可分问题

对于 $M$ 类模式应存在 $M$ 个判别函数 $\ldots$ P56

\section{梯度法}

\subsection{梯度法基本原理}

\paragraph{梯度}%
\label{par:ti_du_}

设函数 $f(\mathbf{Y})$ 是向量 $\mathbf{Y} = [y_1, y_2, \ldots, y_n]^T$ 的函数，则 $f(\mathbf Y)$的梯度定义为：
$$
\nabla f(\mathbf Y) = \frac{d}{d \mathbf Y} f(\matnbf Y) = \Big[ \frac{\partial f}{\partial y_1} , \frac{\partial f}{\partial y_2} , \ldots, \frac{\partial f}{\partial y_n} \Big]^T
$$

梯度向量的最重要的性质之一：指出函数 $f$ 在其自变量增加时，增长最快的方向。

\subsubsection{梯度算法}%
\label{ssub:ti_du_suan_fa_}

P59

\subsection{固定增量法}

\paragraph{准则函数}%
\label{par:zhun_ze_han_shu_}

$J(W, X) = \frac{1}{2}(|W^T X| - W^T X)$

该准则函数有唯一最小值 $0$

\paragraph{推导 $\nabla J$}%
\label{par:tui_dao_nabla_j_}

\paragraph{求 $W(k+1)$}%
\label{par:qiu_w_k_1_}

$$
W(k+1) = W(k) + 
\left\{
\begin{aligned}
	& 0, &W^T(k) X > 0 \\
	& cX, & W^T(k) X \leq 0
\end{aligned}
\right.
$$
\section{最小平方误差算法}

least Mean Square Error, LSME

\paragraph{原理}%
\label{par:yuan_li_}

把对满足 $XW > 0$ 的q求解，改为满足
\begin{equation}
 XW = B
\end{equation}
式中：\\
$B = [b_1, b_2, \ldots, b_i, \ldots, b_N]^T$ 是各分量均为正值的分量

\paragraph{矛盾方程组}%
\label{par:mao_dun_fang_cheng_zu_}

在方程组中，当方程个数多于未知数时，通常没有精确解存在，称为矛盾方程组，一般求近似解。在模式识别中由于训练样本数 $N$ 总是大于模式的维数 $n$，因此在式中方程的个数总是大于未知数 $W$ 分量的个数，是矛盾方程组，只能求近似解。方法是求满足
\begin{equation}
	|| X W^* - B || = \text{极小}
\end{equation}
的 $W^*$，称为最小二乘近似解，也称最优近似解。

\paragraph{准则函数}%
\label{par:zhun_ze_han_shu_}

LMSE 算法的准则函数定义为：
\begin{equation}
	J(W, X, B) = \frac{1}{2} || X W - B ||^2
\end{equation}

\paragraph{LMSE算法递推公式的推导}%
\label{par:lmsesuan_fa_di_tui_gong_shi_de_tui_dao_}

\subparagraph{伪逆矩阵}%
\label{par:wei_ni_ju_zhen_}

$X^# = (X^T X)^{-1}X^T$ 称为 $X$ 的伪逆

\paragraph{模式类别可分性的判别}%
\label{par:mo_shi_lei_bie_ke_fen_xing_de_pan_bie_}

\subparagraph{方法}%
\label{par:fang_fa_}

每次迭代计算后检查一下 $XW(k)$ 的各分量和误差向量 $e(k)$，从而可以判断是否收敛。具体情况见 P66



\subsection{算法特点}

\section{非线性判别函数}

\paragraph{线性判别函数的特点}%
\label{par:xian_xing_pan_bie_han_shu_de_te_dian_}

形式简单，容易学习；用于线性可分的模式类。

\paragraph{非线性判别函数}%
\label{par:fei_xian_xing_pan_bie_han_shu_}

用于线性不可分情况，分段线性，超曲面

\subsection{分段线性判别函数}

\paragraph{特点}%
\label{par:te_dian_}

\begin{itemize}
	\item 相对简单
	\item 能逼近各种形状的超曲面
\end{itemize}

\subsubsection{一般分段线性判别函数}%
\label{ssub:yi_ban_fen_duan_xian_xing_pan_bie_han_shu_}

P70

用各类函数进行分类判决实际上是用各类选出的子类判别函数进行判决 => 判别面由子类的判别函数决定。

\subsubsection{基于距离的分段线性
判别函数}%
\label{ssub:ji_yu_ju_chi_de_fen_duan_xian_xing_pan_bie_han_shu_}

P71

\subsection{分段线性判别函数的学习方法}

\subsubsection{已知子类划分时的学习方法}%

\begin{itemize}
	\item 每个子类看成独立的类
	\item 应用线性可分多类情况3的学习算法
\end{itemize}
\subsubsection{已知子类数目时的学习方法}%
\label{ssub:yi_zhi_zi_lei_shu_mu_shi_de_xue_xi_fang_fa_}

\subsubsection{未知子类数目时的学习方法}%
\label{ssub:wei_zhi_zi_lei_shu_mu_shi_de_xue_xi_fang_fa_}



\chapter{基于统计决策的概率分类法}


\label{ssub:yi_zhi_zi_lei_hua_fen_shi_de_xue_xi_fang_fa_}



\end{document}
